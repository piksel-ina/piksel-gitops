apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: jupyterhub
  namespace: jupyterhub
spec:
  releaseName: jupyterhub
  targetNamespace: jupyterhub
  chart:
    spec:
      chart: jupyterhub
      version: "4.1.0"
      sourceRef:
        kind: HelmRepository
        name: jupyterhub
  interval: 5m0s
  values:
    hub:
      extraConfig:
        profiles: |
          exec(open('/usr/local/etc/jupyterhub/profiles.py').read())

      extraVolumes:
        - name: hub-profile-config
          configMap:
            name: hub-profile-config

      extraVolumeMounts:
        - name: hub-profile-config
          mountPath: /usr/local/etc/jupyterhub/profiles.py
          subPath: profiles.py
          readOnly: true

    # This is the default configuration for single user pods
    singleuser:
      # Use the piksel-core image from ECR
      image:
        name: "686410905891.dkr.ecr.ap-southeast-3.amazonaws.com/piksel-core"
        tag: "jupyter-7b35f73"
        pullPolicy: "Always"

      # Start with JupyterLab
      defaultUrl: "/lab"

      #  Run bash script define in singleuser.yaml
      lifecycleHooks:
        postStart:
          exec:
            command:
              - "bash"
              - "/etc/singleuser/k8s-lifecycle-hook-post-start.sh"

      # Persistent storage configuration
      storage:
        type: dynamic
        capacity: 10Gi
        homeMountPath: /home/jovyan
        dynamic:
          storageClass: gp3
          pvcNameTemplate: claim-{username}
          volumeNameTemplate: volume-{username}
          storageAccessModes:
            - ReadWriteOnce

        # Mount the custom Configmap as a volume
        extraVolumes:
          - name: lifecycle-hook-script
            configMap:
              name: user-etc-singleuser
              defaultMode: 0755

        extraVolumeMounts:
          - name: lifecycle-hook-script
            mountPath: /etc/singleuser
            readOnly: true

      # Default user profile
      profileList:
        - display_name: "Standard Environment"
          description: "Jupyter environment with 2 CPUs and 8GB RAM"
          default: true # This makes it the default
          kubespawner_override:
            cpu_guarantee: 1
            cpu_limit: 2
            mem_guarantee: 8G
            mem_limit: 8G

      # Extra environment variables for single user pods
      extraEnv:
        # // AWS Configuration
        AWS_NO_SIGN_REQUEST: "YES"
        # // GDAL / Rasterio environment variables
        GDAL_DISABLE_READDIR_ON_OPEN: "EMPTY_DIR"
        GDAL_HTTP_MAX_RETRY: "10"
        GDAL_HTTP_RETRY_DELAY: "1"
        GDAL_HTTP_MERGE_CONSECUTIVE_RANGES: "YES"
        # // Dask configuration
        DASK_LABEXTENSION__FACTORY__MODULE: "dask_gateway"
        DASK_LABEXTENSION__FACTORY__CLASS: "GatewayCluster"
        # DASK_GATEWAY__CLUSTER__OPTIONS__IMAGE: "{JUPYTER_IMAGE}"
        # DASK_DISTRIBUTED__DASHBOARD__LINK: "{JUPYTERHUB_SERVICE_PREFIX}proxy/{port}/status"
        # // OpenDataCube configuration
        ODC_DEFAULT_DB_HOSTNAME: "pg-proxy-service.database.svc.cluster.local"
        ODC_DEFAULT_DB_PORT: "6432"
        ODC_DEFAULT_DB_USERNAME: "odcread"
        ODC_DEFAULT_DB_DATABASE: "odc"
        ODC_DEFAULT_INDEX_DRIVER: "postgis"

    # Proxy Configuration
    proxy:
      service:
        type: ClusterIP
      https:
        enabled: true
        type: offload # Let ingress handle SSL termination

    # Culling Configuration
    cull:
      enabled: true
      timeout: 3600 # 1 hour idle timeout
      every: 600 # Check every 10 minutes

